{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1Multivariate Forecasting Using LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPbN9hoqeqVTFSRIlUDSL2e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyksrox/NIKHILR/blob/master/Untitled1Multivariate_Forecasting_Using_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irUr3Y_z0QQv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "df=pd.read_excel('Belafest2_C_train.xlsx')\n",
        "print('Number of rows and columns:', df.shape)\n",
        "df.head(5)\n",
        "\n",
        "\n",
        "df = df.drop('Location',axis=1)\n",
        "\n",
        "df['Holiday2'] = np.where(df['Scheduled Hours(Exc OT)'] <=200, 1, 0)\n",
        "df['Last_7_day_infection'] = df['daily_infections'].rolling(window=7, min_periods=7).mean()\n",
        "df['Last_7_day_deaths'] = df['daily_deaths_unscaled'].rolling(window=7, min_periods=7).mean()\n",
        "df['Last_7_day_deaths_infection_ratio'] = df['Last_7_day_deaths']/df['Last_7_day_infection']\n",
        "df['Weekday']= df['Date'].dt.dayofweek\n",
        "df['Infection_Percentage_Change_Daily'] = df.daily_infections / df.daily_infections.shift(1)\n",
        "df['from_previous_week_day'] = df.daily_infections / df.daily_infections.shift(7)\n",
        "df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df = df.set_index('Date')\n",
        "df.dropna(inplace = True)\n",
        "\n",
        "test_split=round(len(df)*0.20)\n",
        "\n",
        "df_for_training=df[:-70]\n",
        "df_for_testing=df[-70:]\n",
        "\n",
        "print(df_for_training.shape)\n",
        "print(df_for_testing.shape)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_for_training_scaled = scaler.fit_transform(df_for_training)\n",
        "\n",
        "df_for_testing_scaled=scaler.transform(df_for_testing)\n",
        "\n",
        "\n",
        "def createXY(dataset,n_past):\n",
        "    dataX = []\n",
        "    dataY = []\n",
        "    for i in range(n_past, len(dataset)):\n",
        "            dataX.append(dataset[i - n_past:i, 0:dataset.shape[1]])\n",
        "            dataY.append(dataset[i,0])\n",
        "    return np.array(dataX),np.array(data)\n",
        "\n",
        "##taking prediction for 30 days\n",
        "trainX,trainY=createXY(df_for_training_scaled,30)\n",
        "\n",
        "testX,testY=createXY(df_for_testing_scaled,30)\n",
        "\n",
        "##3D numpy array\n",
        "\n",
        "print(\"trainX Shape-- \",trainX.shape)\n",
        "print(\"trainY Shape-- \",trainY.shape)\n",
        "\n",
        "\n",
        "print(testX.shape)\n",
        "print(testY.shape)\n",
        "trainY.shape\n",
        "\n",
        "def build_model(optimizer):\n",
        "    grid_model = Sequential()\n",
        "    grid_model.add(LSTM(50,return_sequences=True,input_shape=(30,11)))\n",
        "    grid_model.add(LSTM(25))\n",
        "    grid_model.add(Dropout(0.2))\n",
        "    grid_model.add(Dense(1))\n",
        "\n",
        "    grid_model.compile(loss = 'mse',optimizer = optimizer)\n",
        "    return grid_model\n",
        "\n",
        "\n",
        "## *** we can add specefic neurons + more epochs & other parameters to grid search --- require GPU\n",
        "## add more optimizers & neurons +epochs\n",
        "grid_model = KerasRegressor(build_fn=build_model,verbose=1,validation_data=(testX,testY))\n",
        "parameters = {'batch_size' : [16,18,20,25,35,45],\n",
        "              'epochs' : [5,10,20,25,35,50],\n",
        "              'optimizer' : ['rmsprop','adam', 'adadelta'] }\n",
        "\n",
        "grid_search  = GridSearchCV(estimator = grid_model,\n",
        "                            param_grid = parameters)\n",
        "##fitting best params\n",
        "grid_search = grid_search.fit(trainX,trainY)\n",
        "\n",
        "\n",
        "grid_search.best_params_\n",
        "my_model_B=grid_search.best_estimator_.model\n",
        "\n",
        "#predicting on test set\n",
        "prediction=my_model_B.predict(testX)\n",
        "#scaler.inverse_transform(prediction)\n",
        "\n",
        "\n",
        "prediction_copies_array = np.repeat(prediction,11, axis=-1)\n",
        "\n",
        "prediction_copies_array\n",
        "pred=scaler.inverse_transform(np.reshape(prediction_copies_array,(len(prediction),11)))[:,0]\n",
        "\n",
        "\n",
        "original_copies_array = np.repeat(testY,11, axis=-1)\n",
        "\n",
        "original_copies_array.shape\n",
        "\n",
        "###inverse scale + plot\n",
        "original=scaler.inverse_transform(np.reshape(original_copies_array,(len(testY),11)))[:,0]\n",
        "\n",
        "plt.plot(original, color = 'red', label = 'RP')\n",
        "plt.plot(pred, color = 'blue', label = 'PP')\n",
        "plt.title(' SP')\n",
        "plt.xlabel('T')\n",
        "plt.ylabel(' P')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "#-----------------------------------------------------------------------------------------\n",
        "#prediction for future 30 days by taking previous 30 into consideration\n",
        "##creating numpy 3d ndarray \n",
        "df_30_days_past=df.iloc[-30:,:]\n",
        "\n",
        "\n",
        "##data to forecast on we can say test x with Shrinkage column as 0 \n",
        "df=pd.read_excel(\"Belafest2_C_test.xlsx\",parse_dates=[\"Date\"],index_col=[0])\n",
        "df_30_days_future.shape\n",
        "\n",
        "df['Holiday2'] = np.where(df['Scheduled Hours(Exc OT)'] <=200, 1, 0)\n",
        "df['Last_7_day_infection'] = df['daily_infections'].rolling(window=7, min_periods=7).mean()\n",
        "df['Last_7_day_deaths'] = df['daily_deaths_unscaled'].rolling(window=7, min_periods=7).mean()\n",
        "df['Last_7_day_deaths_infection_ratio'] = df['Last_7_day_deaths']/df['Last_7_day_infection']\n",
        "df['Weekday']= df['Date'].dt.dayofweek\n",
        "df['Infection_Percentage_Change_Daily'] = df.daily_infections / df.daily_infections.shift(1)\n",
        "df['from_previous_week_day'] = df.daily_infections / df.daily_infections.shift(7)\n",
        "df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df = df.set_index('Date')\n",
        "df.dropna(inplace = True)\n",
        "\n",
        "#positioning \n",
        "df[\"COVID_Shrinkage\"]=0\n",
        "# insert column on the 1st position\n",
        "shiftPos = df.pop(\"COVID_Shrinkage\")\n",
        "df.insert(0, \"COVID_Shrinkage\", shiftPos)\n",
        "\n",
        "#creating df\n",
        "old_scaled_array=scaler.transform(df_30_days_past)\n",
        "new_scaled_array=scaler.transform(df)\n",
        "new_scaled_df=pd.DataFrame(new_scaled_array)\n",
        "new_scaled_df.iloc[:,0]=np.nan\n",
        "full_df=pd.concat([pd.DataFrame(old_scaled_array),new_scaled_df]).reset_index().drop([\"index\"],axis=1)\n",
        "full_df_scaled_array=full_df.values\n",
        "\n",
        "##prediction loop\n",
        "\n",
        "all_data=[]\n",
        "time_step=30\n",
        "for i in range(time_step,len(full_df_scaled_array)):\n",
        "    data_x=[]\n",
        "    data_x.append(full_df_scaled_array[i-time_step:i,0:full_df_scaled_array.shape[1]])\n",
        "    data_x=np.array(data_x)\n",
        "    prediction=my_model_.predict(data_x)\n",
        "    all_data.append(prediction)\n",
        "    full_df.iloc[i,0]=prediction\n",
        "    \n",
        "new_array=np.array(all_data)\n",
        "new_array=new_array.reshape(-1,1)\n",
        "prediction_copies_array = np.repeat(new_array,11, axis=-1)\n",
        "y_pred_future_30_days = scaler.inverse_transform(np.reshape(prediction_copies_array,(len(new_array),11)))[:,0]\n",
        "\n",
        "y_pred_future_30_days =pd.DataFrame(y_pred_future_30_days)\n",
        "\n",
        "df = df.drop('COVID_Shrinkage',axis=1)\n",
        "\n",
        "df.insert(loc = 0,\n",
        "          column = 'C_Shrinkage',\n",
        "          value = y_pred_future_30_days)"
      ]
    }
  ]
}